{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "import time\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import stable_baselines3 as sb\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "# from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "matplotlib.rcParams['axes.labelsize'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patm        = 98000     # Pascals\n",
    "T_amb       = 293       # Kelvin\n",
    "# nR          = 800e-8   # n (moles) * R (cte gases)\n",
    "N           = 6e15      # Num Particulas\n",
    "kb          = 1.38e-23  # J/K\n",
    "\n",
    "rho_agua    = 1000      # kg/m^3\n",
    "viscosidad  = 0.001      # Pa*s == kg/s\n",
    "s_sup       = 7e-2  # N/m\n",
    "\n",
    "# Presion acustica como la suma de varias ondas\n",
    "def ps(t, A, w, d = 0):\n",
    "    # Error Handling es mi pasion\n",
    "    assert len(A) == len(w) == len(d), \"Different shapes\"\n",
    "    r = 0\n",
    "    for i in range(len(A)):\n",
    "        r += A[i] * np.sin(t*w[i] + d[i])  \n",
    "    return r\n",
    "\n",
    "# DiffEqs\n",
    "def fun(t, y, ps_args):\n",
    "    vel, radi, temp = y\n",
    "    vDot = (\n",
    "                - 3/2 * np.power(vel,2)\n",
    "                + (\n",
    "                    3/4 * N*kb*temp/(np.pi*np.power(radi,3))\n",
    "                    - (2*s_sup+4*viscosidad*vel)/radi\n",
    "                    - patm\n",
    "                    - ps(t, *ps_args)\n",
    "                )/rho_agua\n",
    "            )/radi\n",
    "    rDot = vel\n",
    "    tDot = - 2 * temp * vel/radi\n",
    "\n",
    "    return vDot, rDot, tDot   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Normalized (as much as I can) observations\n",
    "El observation space lo voy a hacer un poco mas grande para q tenga margen\n",
    "    Radio always positive in the 1e-3 order  ==>  *100 to scale up\n",
    "    Vel has high range ==> /100 to scale down a little\n",
    "    Temp in logaritmic scale ==> between ~0 and 7\n",
    "'''\n",
    "def observations(R,RDot,T):\n",
    "    return np.array([R*100, RDot/100, np.log10(T)]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-92588.88682039597), 0.5, -300000.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A  = np.array([2,1])\n",
    "w  = np.array([2,1])\n",
    "d  = np.array([np.pi/2,0])\n",
    "\n",
    "t = np.linspace(0, 3*np.pi, 1000)\n",
    "\n",
    "fun(0, [.5, 1e-3, 300], [A,w,d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bubble(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment that follows gym interface.\n",
    "    This is a simple env where the agent must learn to go always left. \n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['data']}\n",
    "\n",
    "    def __init__(self, dt = 1e-5, n_ondas = 1, render_mode = None):\n",
    "        super(Bubble, self).__init__()   \n",
    "\n",
    "        # (R,RDot,T)\n",
    "        self.agent_vars = (np.random.normal(0,1),\n",
    "                           np.random.normal(1e-3, 1e-4),\n",
    "                           np.random.normal(T_amb, 10))\n",
    "\n",
    "        # variables de tiempo\n",
    "        self.t  = 0\n",
    "        self.dt = dt  # timestep en seg\n",
    "\n",
    "        '''\n",
    "        Actions: cambios de Amplitud,frecuencia y fase\n",
    "        '''\n",
    "        self.action_space = spaces.Box(low = np.array([[]]*n_ondas), \n",
    "                                       high = np.array([[]]*n_ondas),\n",
    "                                            shape=(n_ondas,3), dtype=np.float32)\n",
    "        \n",
    "        '''\n",
    "        Observations: Basicamente R,RDot,T\n",
    "        - Si hago los cambios de a pasos tendria que aÃ±adir los valores actuales de A,w,d\n",
    "        '''\n",
    "        self.observation_space = spaces.Box(low = -1, high = 1,\n",
    "                                            shape=(1,), dtype=np.float32)\n",
    "        \n",
    "        '''\n",
    "        Render init Cosas\n",
    "        '''\n",
    "\n",
    "    def reset(self, seed = 0,):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Nuevas Cond Iniciales\n",
    "        self.agent_vars = (np.random.normal(0,1),\n",
    "                           np.random.normal(1e-3, 1e-4),\n",
    "                           np.random.normal(T_amb, 10))\n",
    "        # Render reset cosas\n",
    "        \n",
    "        return observations(*np.ravel(self.agent_vars)), {}\n",
    "    \n",
    "    def step(self, action):\n",
    "\n",
    "        Rdot, R, T = self.agent_vars\n",
    "\n",
    "        # Check action range (if stepped) ----------------------------------- ARAARA\n",
    "        # if abs(action[0]) > 1:\n",
    "        #     raise ValueError(\"Received invalid action={} which is not part of the action space\".format(action))\n",
    "        # else:\n",
    "        #     thDotDot = a = action[0] * 3\n",
    "        \n",
    "        '''\n",
    "         Setear Nuevas variables de A,w,d \n",
    "        '''\n",
    "\n",
    "        sol = solve_ivp(fun, (self.t, self.t + self.dt), \n",
    "                        self.agent_vars, args = [[A,w,d]]\n",
    "                        , max_step = self.dt/10, rtol = 1e-12)\n",
    "        # La AI solo necesita el ultimo dato pero esta todo por si se quisiera graficar\n",
    "        self.agent_vars = sol.y[:,-1] \n",
    "        \n",
    "        ''' [ ] Reward '''\n",
    "        reward = np.log10(T)\n",
    "        \n",
    "        # Additional info\n",
    "        ''' [ ] Hypothesis checking '''\n",
    "        info = {}\n",
    "\n",
    "        return observations(*np.ravel(self.agent_vars)),\\\n",
    "                reward, False, False, info\n",
    "\n",
    "    def render(self, seed = 0):\n",
    "        if self.render_mode == None:\n",
    "            return\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Inv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
